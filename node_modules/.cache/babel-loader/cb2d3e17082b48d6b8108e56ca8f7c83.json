{"ast":null,"code":"var _jsxFileName = \"/Users/abhinavdusi/Desktop/Indicium/src/screens/buy.js\",\n    _s = $RefreshSig$();\n\nimport './buy.css';\nimport { useParams, useNavigate } from 'react-router-dom';\nimport { useState, useEffect } from 'react';\nimport axios from 'axios';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction buy() {\n  console.log(\"Buying paper\");\n}\n\nfunction Author(name) {\n  return /*#__PURE__*/_jsxDEV(\"span\", {\n    children: name\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 12,\n    columnNumber: 9\n  }, this);\n}\n\n_c = Author;\n\nfunction Buy() {\n  _s();\n\n  const {\n    id\n  } = useParams();\n  const [author, setAuthor] = useState(\"Dr. Arjun Khorana\");\n  const [title, setTitle] = useState(\"Title\");\n  const [abstract, setAbstract] = useState(\"Loreum Ipsum\");\n  const [price, setPrice] = useState(10.50);\n  let navigate = useNavigate();\n  useEffect(() => {\n    /*\n    axios({\n        method: 'get',\n        url: `https://localhost:5000/paper/id=${id}`,\n    }).then( res => { \n        setTitle(res.title);\n        setAuthor(res.official_author);\n        setAbstract(res.abstract);\n    }).catch(error => {\n        console.log(error);\n        navigate(\"/404\");\n    })\n    */\n    setTitle(\"The effect of dielectric environment on the neutral and charged dark excitons in WSe2 monolayer\");\n    setAuthor(\"Dr. Arjun \\'Bezos Beta\\' Khorana\");\n    setAbstract(\"Advanced video analytic systems, including scene classification and object detection, have seen widespread success in various domains such as smart cities and autonomous transportation. With an ever-growing number of powerful client devices, there is incentive to move these heavy video analytics workloads from the cloud to mobile devices to achieve low latency and real-time processing and to preserve user privacy. However, most video analytic systems are heavyweight and are trained offline with some pre-defined latency or accuracy requirements. This makes them unable to adapt at runtime in the face of three types of dynamism -- the input video characteristics change, the amount of compute resources available on the node changes due to co-located applications, and the user's latency-accuracy requirements change. In this paper we introduce ApproxDet, an adaptive video object detection framework for mobile devices to meet accuracy-latency requirements in the face of changing content and resource contention scenarios. To achieve this, we introduce a multi-branch object detection kernel (layered on Faster R-CNN), which incorporates a data-driven modeling approach on the performance metrics, and a latency SLA-driven scheduler to pick the best execution branch at runtime. We couple this kernel with approximable video object tracking algorithms to create an end-to-end video object detection system. We evaluate ApproxDet on a large benchmark video dataset and compare quantitatively to AdaScale and YOLOv3. We find that ApproxDet is able to adapt to a wide variety of contention and content characteristics and outshines all baselines, e.g., it achieves 52% lower latency and 11.1% higher accuracy over YOLOv3. \");\n  });\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    id: \"buy-background\",\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      id: \"buy-view\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        id: \"buy-title\",\n        children: title\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 49,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        id: \"buy-authors\",\n        children: Author(author)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 52,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        id: \"buy-abstract\",\n        children: abstract\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 55,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        id: \"buy-button\",\n        onClick: buy,\n        children: [\"BUY $\", Number(price).toFixed(2)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 58,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 48,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 47,\n    columnNumber: 9\n  }, this);\n}\n\n_s(Buy, \"24D8ulN+mofYN6D8kdgmN/X45sE=\", false, function () {\n  return [useParams, useNavigate];\n});\n\n_c2 = Buy;\nexport default Buy;\n\nvar _c, _c2;\n\n$RefreshReg$(_c, \"Author\");\n$RefreshReg$(_c2, \"Buy\");","map":{"version":3,"sources":["/Users/abhinavdusi/Desktop/Indicium/src/screens/buy.js"],"names":["useParams","useNavigate","useState","useEffect","axios","buy","console","log","Author","name","Buy","id","author","setAuthor","title","setTitle","abstract","setAbstract","price","setPrice","navigate","Number","toFixed"],"mappings":";;;AAAA,OAAO,WAAP;AACA,SAASA,SAAT,EAAoBC,WAApB,QAAuC,kBAAvC;AACA,SAASC,QAAT,EAAmBC,SAAnB,QAAoC,OAApC;AACA,OAAOC,KAAP,MAAkB,OAAlB;;;AAEA,SAASC,GAAT,GAAe;AACXC,EAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ;AACH;;AAED,SAASC,MAAT,CAAgBC,IAAhB,EAAsB;AAClB,sBACI;AAAA,cAAOA;AAAP;AAAA;AAAA;AAAA;AAAA,UADJ;AAGH;;KAJQD,M;;AAMT,SAASE,GAAT,GAAe;AAAA;;AACX,QAAM;AAAEC,IAAAA;AAAF,MAASX,SAAS,EAAxB;AACA,QAAM,CAACY,MAAD,EAASC,SAAT,IAAsBX,QAAQ,CAAC,mBAAD,CAApC;AACA,QAAM,CAACY,KAAD,EAAQC,QAAR,IAAoBb,QAAQ,CAAC,OAAD,CAAlC;AACA,QAAM,CAACc,QAAD,EAAWC,WAAX,IAA0Bf,QAAQ,CAAC,cAAD,CAAxC;AACA,QAAM,CAACgB,KAAD,EAAQC,QAAR,IAAoBjB,QAAQ,CAAC,KAAD,CAAlC;AAEA,MAAIkB,QAAQ,GAAGnB,WAAW,EAA1B;AAEAE,EAAAA,SAAS,CAAC,MAAM;AACZ;AACR;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGQY,IAAAA,QAAQ,CAAC,iGAAD,CAAR;AACAF,IAAAA,SAAS,CAAC,kCAAD,CAAT;AACAI,IAAAA,WAAW,CAAC,gsDAAD,CAAX;AACH,GAnBQ,CAAT;AAqBA,sBACI;AAAK,IAAA,EAAE,EAAC,gBAAR;AAAA,2BACI;AAAK,MAAA,EAAE,EAAC,UAAR;AAAA,8BACI;AAAK,QAAA,EAAE,EAAC,WAAR;AAAA,kBACKH;AADL;AAAA;AAAA;AAAA;AAAA,cADJ,eAII;AAAK,QAAA,EAAE,EAAC,aAAR;AAAA,kBACKN,MAAM,CAACI,MAAD;AADX;AAAA;AAAA;AAAA;AAAA,cAJJ,eAOI;AAAK,QAAA,EAAE,EAAC,cAAR;AAAA,kBACKI;AADL;AAAA;AAAA;AAAA;AAAA,cAPJ,eAUI;AAAQ,QAAA,EAAE,EAAC,YAAX;AAAwB,QAAA,OAAO,EAAEX,GAAjC;AAAA,4BAA4CgB,MAAM,CAACH,KAAD,CAAN,CAAcI,OAAd,CAAsB,CAAtB,CAA5C;AAAA;AAAA;AAAA;AAAA;AAAA,cAVJ;AAAA;AAAA;AAAA;AAAA;AAAA;AADJ;AAAA;AAAA;AAAA;AAAA,UADJ;AAgBH;;GA9CQZ,G;UACUV,S,EAMAC,W;;;MAPVS,G;AAgDT,eAAeA,GAAf","sourcesContent":["import './buy.css'\nimport { useParams, useNavigate } from 'react-router-dom'\nimport { useState, useEffect } from 'react'\nimport axios from 'axios'\n\nfunction buy() {\n    console.log(\"Buying paper\");\n}\n\nfunction Author(name) {\n    return (\n        <span>{name}</span>\n    );\n}\n\nfunction Buy() {\n    const { id } = useParams();\n    const [author, setAuthor] = useState(\"Dr. Arjun Khorana\");\n    const [title, setTitle] = useState(\"Title\");\n    const [abstract, setAbstract] = useState(\"Loreum Ipsum\");\n    const [price, setPrice] = useState(10.50);\n\n    let navigate = useNavigate()\n\n    useEffect(() => {\n        /*\n        axios({\n            method: 'get',\n            url: `https://localhost:5000/paper/id=${id}`,\n        }).then( res => { \n            setTitle(res.title);\n            setAuthor(res.official_author);\n            setAbstract(res.abstract);\n        }).catch(error => {\n            console.log(error);\n            navigate(\"/404\");\n        })\n        */\n\n\n        setTitle(\"The effect of dielectric environment on the neutral and charged dark excitons in WSe2 monolayer\");\n        setAuthor(\"Dr. Arjun \\'Bezos Beta\\' Khorana\");\n        setAbstract(\"Advanced video analytic systems, including scene classification and object detection, have seen widespread success in various domains such as smart cities and autonomous transportation. With an ever-growing number of powerful client devices, there is incentive to move these heavy video analytics workloads from the cloud to mobile devices to achieve low latency and real-time processing and to preserve user privacy. However, most video analytic systems are heavyweight and are trained offline with some pre-defined latency or accuracy requirements. This makes them unable to adapt at runtime in the face of three types of dynamism -- the input video characteristics change, the amount of compute resources available on the node changes due to co-located applications, and the user's latency-accuracy requirements change. In this paper we introduce ApproxDet, an adaptive video object detection framework for mobile devices to meet accuracy-latency requirements in the face of changing content and resource contention scenarios. To achieve this, we introduce a multi-branch object detection kernel (layered on Faster R-CNN), which incorporates a data-driven modeling approach on the performance metrics, and a latency SLA-driven scheduler to pick the best execution branch at runtime. We couple this kernel with approximable video object tracking algorithms to create an end-to-end video object detection system. We evaluate ApproxDet on a large benchmark video dataset and compare quantitatively to AdaScale and YOLOv3. We find that ApproxDet is able to adapt to a wide variety of contention and content characteristics and outshines all baselines, e.g., it achieves 52% lower latency and 11.1% higher accuracy over YOLOv3. \");\n    });\n\n    return (\n        <div id=\"buy-background\">\n            <div id=\"buy-view\"> \n                <div id=\"buy-title\">\n                    {title}\n                </div>\n                <div id=\"buy-authors\">\n                    {Author(author)}\n                </div>\n                <div id=\"buy-abstract\"> \n                    {abstract}\n                </div>\n                <button id=\"buy-button\" onClick={buy}>BUY ${Number(price).toFixed(2)}</button>\n            </div>\n        </div>\n    );\n}\n\nexport default Buy;\n"]},"metadata":{},"sourceType":"module"}